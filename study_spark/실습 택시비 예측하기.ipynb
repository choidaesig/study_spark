{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9e91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "MAX_MEMORY=\"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediciton\")\\\n",
    "                .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "                .config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a035e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"C:\\\\Users\\\\daesi\\\\Downloads\\\\빅데이터 소스코드\\\\소스코드\\\\study_spark\\data\"\n",
    "trip_files = \"\\\\trips\\\\*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea05e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df = spark.read.csv(f\"file:///{directory}\\\\{trip_files}\", inferSchema=True, header=True)\n",
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6760cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003703c",
   "metadata": {},
   "source": [
    "운행 거리(`trip distance`)에 따른 요금(`total amount`)를 예측하는 회귀 모델을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3330536",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    trip_distance,\n",
    "    total_amount\n",
    "FROM trips\n",
    "\n",
    "WHERE total_amount < 5000\n",
    "  AND total_amount > 0\n",
    "  AND trip_distance > 0\n",
    "  AND trip_distance < 500\n",
    "  AND passenger_count < 4\n",
    "  AND TO_DATE(tpep_pickup_datetime) >= \"2021-01-01\"\n",
    "  AND TO_DATE(tpep_pickup_datetime) < \"2021-08-01\"\n",
    "\"\"\"\n",
    "\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca78c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|trip_distance|total_amount|\n",
      "+-------------+------------+\n",
      "|         16.5|       70.07|\n",
      "|         1.13|       11.16|\n",
      "|         2.68|       18.59|\n",
      "|         12.4|        43.8|\n",
      "|          9.7|        32.3|\n",
      "+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a273f6",
   "metadata": {},
   "source": [
    "trip_distance는 X, total_amount는 Y\n",
    "\n",
    "머신 러닝 모델 y=f(x)를 이용해서 예측 > 회귀분석\n",
    "1. train/test로 데이터 셋 split\n",
    "2. x값을 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7e5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa68ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500253, 2625787)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88fcca",
   "metadata": {},
   "source": [
    "1. 하나 이상의 독립 변수를 하나의 벡터로 묶는 것 > Feature Vecotrization\n",
    "    - x Feature의 형식을 1차원 배열로 (벡터)로 바꿔야한다.\n",
    "    - vectorAssembler 사용\n",
    "    - 이것을 묶어서 2차원 형태로 만든다 > 벡터 어셈블러\n",
    "\n",
    "`feature`는 `vector` 형태로 존재해야 하기 때문에 1차원 배열로 만들어 주는 `VectorAssembler` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24d8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+\n",
      "|trip_distance|total_amount|features|\n",
      "+-------------+------------+--------+\n",
      "|         0.01|        3.05|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "+-------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "# inputCols에 지정된 컬럼의 데이터들을 1차원 배열 형식으로 묶어서\n",
    "# outputCol에 지정된 컬럼의 이름으로 새로운 컬럼을 생성\n",
    "\n",
    "\n",
    "vassembler = VectorAssembler(inputCols=[\"trip_distance\"], outputCol=\"features\")\n",
    "vtrain_df  = vassembler.transform(train_df)\n",
    "\n",
    "vtrain_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67eeb9a",
   "metadata": {},
   "source": [
    "# 모델 생성 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43fdc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5b2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    maxIter=50,  #훈련횟수\n",
    "    labelCol = \"total_amount\", # 훈련할 컬럼, 종속변수\n",
    "    featuresCol = \"features\"  # 특성 컬럼 이름 지정, 독립변수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7decef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형회귀 모델 학습\n",
    "# 학습용 벡터 어셈블러 객체 > 데이터\n",
    "\n",
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923c46c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+\n",
      "|trip_distance|total_amount|features|\n",
      "+-------------+------------+--------+\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "+-------------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터도 vector assemble 형식으로 변환.\n",
    "#  테스트 데이터 세트를 위해서 Transformer를 새로 마세요!!! 반드시 훈련 데이터 세트에서 사용했던 Transformer를 사용\n",
    "vtest_df = vassembler.transform(test_df)\n",
    "vtest_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd787a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+-----------------+\n",
      "|trip_distance|total_amount|features|       prediction|\n",
      "+-------------+------------+--------+-----------------+\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.8|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.8|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.8|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.8|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.8|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.8|  [0.01]|9.430440745312902|\n",
      "+-------------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#테스트 데이터로 예측하기(transform)\n",
    "\n",
    "test_predictions = model.transform(vtest_df)\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd2420",
   "metadata": {},
   "source": [
    "prediction 과 total_amount 값을 비교 > 차이가 많이 난다.\n",
    "\n",
    "--실제로 오차를 확인하자--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3edd7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.30781413196623"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b416493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7648633777017714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R^2\n",
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bd9d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_distance|\n",
      "+-------------+\n",
      "|          1.1|\n",
      "|          5.5|\n",
      "|         10.5|\n",
      "|          3.0|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실제 데이터를 만들어서 예측하기\n",
    "from pyspark.sql.types import DoubleType\n",
    "distance_list = [1.1, 5.5, 10.5, 3.0]\n",
    "distance_df   = spark.createDataFrame(distance_list, DoubleType()).toDF(\"trip_distance\")\n",
    "\n",
    "distance_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55957a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|trip_distance|features|\n",
      "+-------------+--------+\n",
      "|          1.1|   [1.1]|\n",
      "|          5.5|   [5.5]|\n",
      "|         10.5|  [10.5]|\n",
      "|          3.0|   [3.0]|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vdistance_df = vassembler.transform(distance_df)\n",
    "vdistance_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34b19a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------------+\n",
      "|trip_distance|features|        prediction|\n",
      "+-------------+--------+------------------+\n",
      "|          1.1|   [1.1]|12.672809485363317|\n",
      "|          5.5|   [5.5]|25.761270454374163|\n",
      "|         10.5|  [10.5]| 40.63452155552285|\n",
      "|          3.0|   [3.0]|18.324644903799822|\n",
      "+-------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(vdistance_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a47f4",
   "metadata": {},
   "source": [
    "# 두번째 모델\\\n",
    "\n",
    "feature를 늘려서 예측, 데이터 종류 증가\n",
    "출발지, 도착지, 소요시간, 요일추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a953e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "    total_amount\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\"\n",
    "\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f824b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|               138|                265|         16.5|          0|     Monday|       70.07|\n",
      "|              1|                68|                264|         1.13|          0|     Monday|       11.16|\n",
      "|              1|               239|                262|         2.68|          0|     Monday|       18.59|\n",
      "|              1|               186|                 91|         12.4|          0|     Monday|        43.8|\n",
      "|              2|               132|                265|          9.7|          0|     Monday|        32.3|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fce3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98749e",
   "metadata": {},
   "source": [
    "# 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "904384a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762f757",
   "metadata": {},
   "source": [
    "`One Hot Encode` stage\n",
    "- `pickup_location_id`\n",
    "- `dropoff_location_id`\n",
    "- `day_of_week`\n",
    "\n",
    "위 세 `feature`는 범주형 (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc5e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_c84341797d30,\n",
       " OneHotEncoder_152c7e2d1754,\n",
       " StringIndexer_1d3da27504af,\n",
       " OneHotEncoder_97c8d500de16,\n",
       " StringIndexer_8c9764df0816,\n",
       " OneHotEncoder_91674f9f33aa]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StringIndexer : String 값을 Integer로 바꿔준다.\n",
    "# OneHotEncoder : StringIndexer에 의해 정수가 된 값을 OneHotEncoding을 시켜준다.\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "# OHE 할 컬럼 지정\n",
    "cat_features = [\n",
    "    \"pickup_location_id\",\n",
    "    \"dropoff_location_id\",\n",
    "    \"day_of_week\"\n",
    "]\n",
    "\n",
    "for c in cat_features:\n",
    "    cat_indexer = StringIndexer(inputCol=c, outputCol=c+\"_idx\").setHandleInvalid(\"keep\")\n",
    "    onehot_encoder = OneHotEncoder(inputCols=[cat_indexer.getOutputCol()], outputCols=[c + \"_onehot\"])\n",
    "    stages += [cat_indexer, onehot_encoder]\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fb199",
   "metadata": {},
   "source": [
    "`Numerical Data` Preprocessing stage > 수치형 데이터 전처리\n",
    "\n",
    "대상 컬럼\n",
    "- `passenger_count`\n",
    "- `trip_distance`\n",
    "- `pickup_time`\n",
    "\n",
    "standard scaler > 표준화 > 아웃라이어의 보정이 가능하다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a0d9190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_c84341797d30,\n",
       " OneHotEncoder_152c7e2d1754,\n",
       " StringIndexer_1d3da27504af,\n",
       " OneHotEncoder_97c8d500de16,\n",
       " StringIndexer_8c9764df0816,\n",
       " OneHotEncoder_91674f9f33aa,\n",
       " VectorAssembler_c22685fb1b94,\n",
       " StandardScaler_47c63580ab93,\n",
       " VectorAssembler_318e938986f8,\n",
       " StandardScaler_8a0350a6bdc5,\n",
       " VectorAssembler_162c379d2f86,\n",
       " StandardScaler_7c3b5203e874]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 컬럼의 데이터를 벡터화 시키고, 표준화 StandardScaler를 수행한다.\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "num_features = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"pickup_time\"\n",
    "]\n",
    "\n",
    "for n in num_features:\n",
    "    num_assembler = VectorAssembler(inputCols=[n], outputCol = n + \"_vector\")\n",
    "    num_scaler    = StandardScaler(inputCol = num_assembler.getOutputCol(), outputCol= n+\"_scaled\")\n",
    "    stages += [num_assembler, num_scaler]\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db22355",
   "metadata": {},
   "source": [
    "category, numeric 형식으로 각각 작업된 벡터 결과물들을 하나로 합쳐주기 ( `VectorAssembler` )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2933d18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _onehot이 붙은 컬럼과 _scaled가 붙은 컬럼만 있으면 된다.\n",
    "assembler_inputs = [c + \"_onehot\" for c in cat_features ] + [ n + \"_scaled\" for n in num_features ]\n",
    "assembler_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "711c4225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_c84341797d30,\n",
       " OneHotEncoder_152c7e2d1754,\n",
       " StringIndexer_1d3da27504af,\n",
       " OneHotEncoder_97c8d500de16,\n",
       " StringIndexer_8c9764df0816,\n",
       " OneHotEncoder_91674f9f33aa,\n",
       " VectorAssembler_c22685fb1b94,\n",
       " StandardScaler_47c63580ab93,\n",
       " VectorAssembler_318e938986f8,\n",
       " StandardScaler_8a0350a6bdc5,\n",
       " VectorAssembler_162c379d2f86,\n",
       " StandardScaler_7c3b5203e874,\n",
       " VectorAssembler_e02b03865123]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols= assembler_inputs, outputCol=\"feature_vector\")\n",
    "stages += [assembler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41012446",
   "metadata": {},
   "source": [
    "# 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b78e21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transformer = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10304010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vector: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform 을 이용해 데이터 변환\n",
    "vtrain_df = fitted_transformer.transform(train_df)\n",
    "vtrain_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b445ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      feature_vector|\n",
      "+--------------------+\n",
      "|(533,[62,311,527,...|\n",
      "|(533,[62,280,526,...|\n",
      "|(533,[62,280,527,...|\n",
      "|(533,[62,280,528,...|\n",
      "|(533,[62,299,523,...|\n",
      "|(533,[62,288,523,...|\n",
      "|(533,[62,264,526,...|\n",
      "|(533,[62,301,523,...|\n",
      "|(533,[62,301,523,...|\n",
      "|(533,[62,282,527,...|\n",
      "|(533,[62,275,529,...|\n",
      "|(533,[62,293,527,...|\n",
      "|(533,[62,284,529,...|\n",
      "|(533,[63,319,525,...|\n",
      "|(533,[63,319,524,...|\n",
      "|(533,[63,319,523,...|\n",
      "|(533,[63,339,526,...|\n",
      "|(533,[63,276,524,...|\n",
      "|(533,[63,355,529,...|\n",
      "|(533,[63,292,528,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vtrain_df.select(\"feature_vector\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed6a15",
   "metadata": {},
   "source": [
    "**모델 생성**\n",
    "`VectorAssembler`를 이용해 `feature`들이 모여있는 `feature_vector` 컬럼을 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b54b72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(\n",
    "    maxIter=50,\n",
    "    solver=\"normal\",\n",
    "    labelCol=\"total_amount\",\n",
    "    featuresCol=\"feature_vector\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d74718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4d620d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = fitted_transformer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44119905",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "079228c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[passenger_count: int, pickup_location_id: int, dropoff_location_id: int, trip_distance: double, pickup_time: int, day_of_week: string, total_amount: double, pickup_location_id_idx: double, pickup_location_id_onehot: vector, dropoff_location_id_idx: double, dropoff_location_id_onehot: vector, day_of_week_idx: double, day_of_week_onehot: vector, passenger_count_vector: vector, passenger_count_scaled: vector, trip_distance_vector: vector, trip_distance_scaled: vector, pickup_time_vector: vector, pickup_time_scaled: vector, feature_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과물은 바뀌지 않기 때문에 cache로 지정해서 메모리를 낭비하지 않도록 하는 것이 좋다.\n",
    "predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dc15a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+\n",
      "|trip_distance|day_of_week|total_amount|        prediction|\n",
      "+-------------+-----------+------------+------------------+\n",
      "|          1.0|    Tuesday|       10.55|12.695522792729275|\n",
      "|          1.7|   Saturday|        13.3| 14.45055801477692|\n",
      "|          4.1|     Friday|        21.3|21.108271361254214|\n",
      "|         11.5|     Sunday|        41.3| 40.87993984204375|\n",
      "|          1.7|   Saturday|       14.15| 13.90693298261399|\n",
      "|          0.7|  Wednesday|         5.8|  9.62248222618894|\n",
      "|          5.0|  Wednesday|        24.3|21.147909957146926|\n",
      "|          1.5|   Thursday|         8.8| 9.969750900636763|\n",
      "|         13.4|     Monday|       66.35| 62.65097273030503|\n",
      "|         15.0|     Monday|       70.67| 66.37330532523579|\n",
      "|         14.2|  Wednesday|       85.65| 89.80098581271078|\n",
      "|          0.1|  Wednesday|        55.3|12.483544948638677|\n",
      "|          3.9|    Tuesday|       21.95|23.136774384461823|\n",
      "|          4.7|   Thursday|        27.8| 23.06253705950276|\n",
      "|          1.4|   Thursday|       21.12|15.791556867253746|\n",
      "|          1.6|   Thursday|       13.55| 16.66388464261349|\n",
      "|          4.0|   Thursday|        20.8| 21.36982589020375|\n",
      "|          4.3|  Wednesday|       21.05| 21.84988605314538|\n",
      "|          4.9|   Thursday|        21.3|23.491569972722782|\n",
      "|          2.4|  Wednesday|       16.55|17.843846452773935|\n",
      "+-------------+-----------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select([\"trip_distance\", \"day_of_week\", \"total_amount\", \"prediction\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38bac821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6485201652667625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7a6bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80849012500813"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6285a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e94760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
